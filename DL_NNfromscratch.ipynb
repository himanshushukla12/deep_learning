{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshushukla12/deep_learning/blob/main/DL_NNfromscratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **There are two questions at the end of this notebook. Each one contain 5 marks question 3 is just for practice it is not for the evaultion.**"
      ],
      "metadata": {
        "id": "WBd3KuTHSx3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Jo34Bjd1HBU-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "SOXl_45uHhqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_indep=pd.read_csv('train.csv.csv')\n",
        "t_indep=t_indep.drop(t_indep.columns[[0]],axis=1)\n",
        "t_dep=pd.read_csv('test.csv.csv')\n",
        "t_dep=t_dep.drop(t_dep.columns[[0]],axis=1)"
      ],
      "metadata": {
        "id": "YbIO8RGvHYpS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89FakRkEblRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t_indep)\n",
        "print(t_dep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZE8tKTsIRYx",
        "outputId": "186b21fb-1353-4db8-86be-527a579ed60c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  \\\n",
            "0    22.0      1      0  2.110213         1           0         0         0   \n",
            "1    38.0      1      0  4.280593         0           1         1         0   \n",
            "2    26.0      0      0  2.188856         0           1         0         0   \n",
            "3    35.0      1      0  3.990834         0           1         1         0   \n",
            "4    35.0      0      0  2.202765         1           0         0         0   \n",
            "..    ...    ...    ...       ...       ...         ...       ...       ...   \n",
            "886  27.0      0      0  2.639057         1           0         0         1   \n",
            "887  19.0      0      0  3.433987         0           1         1         0   \n",
            "888  24.0      1      2  3.196630         0           1         0         0   \n",
            "889  26.0      0      0  3.433987         1           0         1         0   \n",
            "890  32.0      0      0  2.169054         1           0         0         0   \n",
            "\n",
            "     Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
            "0           1           0           0           1  \n",
            "1           0           1           0           0  \n",
            "2           1           0           0           1  \n",
            "3           0           0           0           1  \n",
            "4           1           0           0           1  \n",
            "..        ...         ...         ...         ...  \n",
            "886         0           0           0           1  \n",
            "887         0           0           0           1  \n",
            "888         1           0           0           1  \n",
            "889         0           1           0           0  \n",
            "890         1           0           1           0  \n",
            "\n",
            "[891 rows x 12 columns]\n",
            "     Survived\n",
            "0           0\n",
            "1           1\n",
            "2           1\n",
            "3           1\n",
            "4           0\n",
            "..        ...\n",
            "886         0\n",
            "887         1\n",
            "888         0\n",
            "889         1\n",
            "890         0\n",
            "\n",
            "[891 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So PyTorch tensors allow us to use gradients and make life easier, so we'll convert these dataframe values into those\n"
      ],
      "metadata": {
        "id": "x-S4wJZeImKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_dep=torch.tensor(t_dep.values,dtype=torch.float)\n",
        "t_indep=torch.tensor(t_indep.values,dtype=torch.float)"
      ],
      "metadata": {
        "id": "ozAr0M2kIYt7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t_indep.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhnmtoDSI-d-",
        "outputId": "08f17ebc-a4bf-4ceb-fce0-9181ea96d552"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([891, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WYCuXo7I_vS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up a Linear Model"
      ],
      "metadata": {
        "id": "cF2Nj65QJK32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "n_coeff=t_indep.size()[1]\n",
        "coeffs=torch.rand(n_coeff)-0.5 #random values in range -0.5 to 0.5\n",
        "coeffs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcQ5EqW4JMRd",
        "outputId": "52a846b8-6f30-468a-815a-ae2d1fda49b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3823,  0.4150, -0.1171,  0.4593, -0.1096,  0.1009, -0.2434,  0.2936,\n",
              "         0.4408, -0.3668,  0.4346,  0.0936])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing values in each column\n",
        "\n",
        "This is done to prevent any one column dominating the prediction results, since a linear model is row*coeffs, very high initial values in some columns will lead to some columns dominating the final answer which we don't want"
      ],
      "metadata": {
        "id": "azttAfbBKfij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vals,indices = t_indep.max(dim=0)\n",
        "t_indep = t_indep / vals  #v cool line of code, think about why"
      ],
      "metadata": {
        "id": "WBkHocQOKHy9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=(t_indep*coeffs).sum(axis=1)"
      ],
      "metadata": {
        "id": "jCDD7t2xMmCR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuaCiYBNMtzt",
        "outputId": "5481e0fe-f744-4788-ddac-532d25554e45"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7371, 0.0391, 0.9206, 0.4639, 0.7542, 1.0459, 0.2906, 0.7982, 0.9089,\n",
              "        0.3994])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=torch.abs(preds-t_dep).mean()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGe3svgVMv0A",
        "outputId": "e107e27b-9ae6-4970-be7d-7152a5ccea06"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5584)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making functions for loss and predictions"
      ],
      "metadata": {
        "id": "Iqs_PBInNG0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(coeffs,indeps):\n",
        "  return (indeps*coeffs).sum(axis=1)\n",
        "\n",
        "def calc_loss(coeffs,indeps,deps):\n",
        "  return torch.abs(pred(coeffs,indeps)-deps).mean()"
      ],
      "metadata": {
        "id": "HgxCzmLeM3iL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.requires_grad_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTfWR-hJa89N",
        "outputId": "1068d997-d9fb-4053-f9aa-7e88b696c90b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3823,  0.4150, -0.1171,  0.4593, -0.1096,  0.1009, -0.2434,  0.2936,\n",
              "         0.4408, -0.3668,  0.4346,  0.0936], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing gradient descent"
      ],
      "metadata": {
        "id": "dgRgCGKpNYoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.requires_grad_() #enables gradients for coeffs tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnZUx6ONW-W",
        "outputId": "f0df3479-0bfb-413f-9fe8-3b474562c04c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3823,  0.4150, -0.1171,  0.4593, -0.1096,  0.1009, -0.2434,  0.2936,\n",
              "         0.4408, -0.3668,  0.4346,  0.0936], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sshxzU--NlD8",
        "outputId": "a00e85e3-29aa-4640-df96-2dd86f036e1c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5584, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "#compute gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZNmXS64pbDh7",
        "outputId": "1a278e2b-b767-4775-e9c8-9f5100eeec71"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-7072c9c840b3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-UjpEz-NtkH",
        "outputId": "7e47bee8-95c7-4cb2-cce0-7e6ce24a24ca"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0775,  0.0306,  0.0236,  0.1006,  0.1234,  0.1237, -0.0350,  0.0523,\n",
              "         0.2297, -0.0406,  0.0847,  0.2029])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.grad.zero_()\n",
        "loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "  coeffs.sub_(coeffs.grad*0.1)\n",
        "  coeffs.grad.zero_()\n",
        "  print(calc_loss(coeffs,t_indep,t_dep))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeZyyVPIb10H",
        "outputId": "e01c9b37-9f06-42e3-b4b5-54ec45dae852"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5439)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(coeffs,indeps):\n",
        "  return (indeps*coeffs).sum(axis=1)\n",
        "def calc_loss(coeffs,indeps,deps):\n",
        "  return torch.abs(pred(coeffs,indeps)-deps).mean()\n",
        "#loss.backward() #calculates gradients"
      ],
      "metadata": {
        "id": "uFnT8Fo_NrDW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each time you call loss.backwards, newly calculated gradients are accumulated (or added to current gradients)\n",
        "\n",
        "We use tensor.grad.zero_() to make the gradients zero after each step"
      ],
      "metadata": {
        "id": "9mWJEDwPN0Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.grad.zero_()\n",
        "loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "  coeffs.sub_(coeffs.grad*0.1)\n",
        "  coeffs.grad.zero_()\n",
        "  print(calc_loss(coeffs,t_indep,t_dep))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1YWhxXnNxuk",
        "outputId": "d07e1694-2530-4821-cb86-4f291cd97f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5439)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making functions for this"
      ],
      "metadata": {
        "id": "9DZqLzt-Onr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_coeffs(coeffs,lr):\n",
        "  coeffs.sub_(coeffs.grad*lr)\n",
        "  coeffs.grad.zero_()"
      ],
      "metadata": {
        "id": "I4Y4tXa-Obh5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_epoch(coeffs,lr):\n",
        "  loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    update_coeffs(coeffs,lr)\n",
        "    print(f\"{loss:.3f}\", end=\"; \")\n"
      ],
      "metadata": {
        "id": "mfiaKkbKOuVR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_coeffs():\n",
        "  return (torch.rand(n_coeff)-0.5).requires_grad_()\n"
      ],
      "metadata": {
        "id": "6FNamSw9PAQ3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs=3, lr=0.01):\n",
        "    torch.manual_seed(442)\n",
        "    coeffs = init_coeffs()\n",
        "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
        "    return coeffs"
      ],
      "metadata": {
        "id": "yzpj7KRxPMKF"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMFuZ7OMPRPy",
        "outputId": "9001d3cf-4e26-4394-e81e-29a7276e1fc9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.531; 0.531; 0.530; "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4616,  0.1385,  0.2409, -0.2246, -0.2629, -0.3126,  0.4895,  0.3135,\n",
              "         0.2806, -0.4335,  0.2114,  0.3583], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "coeffs.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wul5nQP0eVq6",
        "outputId": "a0edb39d-bddc-4297-c99a-cda306a8902b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coeffs.grad) #shows us that the model has pretty much converged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjvSfBnTYyZK",
        "outputId": "7d07e93f-a308-4869-96de-65e4698d14b8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a full neural network"
      ],
      "metadata": {
        "id": "IFL0aRIeSmdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#oneá¹atrix multi-> activation function->matrix mult-> act func"
      ],
      "metadata": {
        "id": "WexvT2oAfTRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def preds(coeffs, indeps):\n",
        "    l1,l2,const = coeffs\n",
        "    res = F.relu(indeps@l1) # '@' is an optimized matrix product in python\n",
        "    res = res@l2 + const\n",
        "    return torch.sigmoid(res)\n",
        "\n"
      ],
      "metadata": {
        "id": "HzrXhsw0ZmJQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(coeffs,indeps,deps):\n",
        "  return torch.abs(preds(coeffs,indeps)-deps).mean()"
      ],
      "metadata": {
        "id": "laEnaVCvZfV1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_epoch(coeffs,lr):\n",
        "  loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    update_coeffs(coeffs,lr)\n",
        "    print(f\"{loss:.3f}\", end=\"; \")"
      ],
      "metadata": {
        "id": "oGOB5iNSZX87"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs=300, lr=0.1):\n",
        "    torch.manual_seed(442)\n",
        "    coeffs = init_coeffs()\n",
        "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
        "    return coeffs"
      ],
      "metadata": {
        "id": "R5dXI41AVSQb"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_coeffs(n_hidden=60):\n",
        "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n",
        "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
        "    const = torch.rand(1)[0]\n",
        "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
      ],
      "metadata": {
        "id": "S12bjOPdPTOW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_coeffs(coeffs, lr=0.1):\n",
        "    for layer in coeffs:\n",
        "        layer.sub_(layer.grad * lr)\n",
        "        layer.grad.zero_()"
      ],
      "metadata": {
        "id": "_cIXRlSiU28p"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs=train_model()\n",
        "# update_coeffs(l1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmtMp_OMVAW5",
        "outputId": "97fdfd15-3cdd-4a33-a27b-b2d97b6eae3b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.524; 0.520; 0.518; 0.516; 0.514; 0.512; 0.510; 0.508; 0.506; 0.504; 0.501; 0.499; 0.497; 0.494; 0.492; 0.490; 0.487; 0.485; 0.483; 0.480; 0.478; 0.476; 0.473; 0.471; 0.468; 0.466; 0.463; 0.461; 0.459; 0.456; 0.454; 0.451; 0.449; 0.446; 0.444; 0.441; 0.439; 0.436; 0.434; 0.431; 0.429; 0.426; 0.424; 0.421; 0.418; 0.416; 0.413; 0.411; 0.408; 0.405; 0.403; 0.400; 0.397; 0.395; 0.392; 0.389; 0.386; 0.384; 0.381; 0.378; 0.375; 0.373; 0.370; 0.367; 0.364; 0.362; 0.359; 0.357; 0.354; 0.351; 0.349; 0.346; 0.344; 0.341; 0.339; 0.336; 0.334; 0.332; 0.329; 0.327; 0.325; 0.323; 0.321; 0.318; 0.316; 0.314; 0.312; 0.310; 0.309; 0.307; 0.305; 0.303; 0.301; 0.300; 0.298; 0.296; 0.295; 0.293; 0.292; 0.290; 0.289; 0.287; 0.286; 0.285; 0.283; 0.282; 0.281; 0.279; 0.278; 0.277; 0.276; 0.275; 0.274; 0.273; 0.272; 0.271; 0.270; 0.269; 0.268; 0.267; 0.266; 0.265; 0.264; 0.263; 0.263; 0.262; 0.261; 0.260; 0.259; 0.259; 0.258; 0.257; 0.257; 0.256; 0.255; 0.255; 0.254; 0.253; 0.253; 0.252; 0.252; 0.251; 0.251; 0.250; 0.250; 0.249; 0.249; 0.248; 0.248; 0.247; 0.247; 0.246; 0.246; 0.245; 0.245; 0.244; 0.244; 0.244; 0.243; 0.243; 0.242; 0.242; 0.242; 0.241; 0.241; 0.241; 0.240; 0.240; 0.240; 0.239; 0.239; 0.239; 0.238; 0.238; 0.238; 0.237; 0.237; 0.237; 0.236; 0.236; 0.236; 0.236; 0.235; 0.235; 0.235; 0.235; 0.234; 0.234; 0.234; 0.234; 0.233; 0.233; 0.233; 0.233; 0.232; 0.232; 0.232; 0.232; 0.232; 0.231; 0.231; 0.231; 0.231; 0.231; 0.230; 0.230; 0.230; 0.230; 0.230; 0.229; 0.229; 0.229; 0.229; 0.229; 0.229; 0.228; 0.228; 0.228; 0.228; 0.228; 0.228; 0.227; 0.227; 0.227; 0.227; 0.227; 0.227; 0.226; 0.226; 0.226; 0.226; 0.226; 0.226; 0.226; 0.225; 0.225; 0.225; 0.225; 0.225; 0.225; 0.225; 0.224; 0.224; 0.224; 0.224; 0.224; 0.224; 0.224; 0.224; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.218; 0.218; "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(coeffs): return (t_dep.bool()==(preds(coeffs,t_indep)>0.5)).float().mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "ldox7Va5VB-O"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc(coeffs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7YDLChmdtr_",
        "outputId": "3b2ad88d-072f-4469-b25b-a81351b9c4c2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7868)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluative Component:\n",
        "1. Create a train/test split from the dataset\n",
        "\n",
        "2. Evaluate the testing split and it's accuracy\n",
        "\n",
        "optional: 3. Make the neural network 3 layer and evaluate accuracy"
      ],
      "metadata": {
        "id": "UYDON7ACeR7R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z19cOaQod0Gd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}